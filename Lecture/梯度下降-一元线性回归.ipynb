{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 梯度下降算法： 一元线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 生成数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实例数m=100, 一个特征x， 输出为y\n",
    "\n",
    "$y = \\theta_0 + \\theta_1x + \\epsilon$, 假设$x$为服从标准正态分布的变量，$\\epsilon$也是服从标准正态分布的变量, $\\theta_0=1$, $\\theta_1=5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 生成特征x (一维)： 假设x是服从标准正态的变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用numpy中的random.normal函数：\n",
    "https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_sample = 100 ## 实例数为100\n",
    "\n",
    "x = np.random.normal(loc=0.0, scale = 1.0, size=(n_sample)) ## loc代表均值，scale代表标准差，size代表数据的维数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.17457231, -1.88734069,  0.27378712, -0.77648721, -0.55958724,\n",
       "       -0.47063225, -0.73808536,  1.83957058,  0.00309406,  0.75130573,\n",
       "       -0.33413325, -0.67389771,  0.17315008,  1.85041587, -0.87348334,\n",
       "       -1.96649657,  0.82003852, -0.78804404,  0.35489975, -0.49567212,\n",
       "        0.07673238,  0.30729399,  2.68804152,  0.13240582,  0.23217722,\n",
       "       -1.83258787,  1.28117284,  0.54196538, -0.32533976, -1.11867033,\n",
       "       -0.01498879,  1.0623883 ,  0.37982087, -0.55896314,  0.31840562,\n",
       "       -0.73290621, -2.27582182, -0.92759081, -0.27458454,  0.63341354,\n",
       "        0.61544656, -0.84228229,  1.60131077, -1.6459211 ,  0.56044429,\n",
       "       -0.2772544 , -0.63481569,  0.180513  ,  0.16081974,  1.25953333,\n",
       "       -0.77834629,  0.04685155,  0.07263471,  0.15991183,  1.1204807 ,\n",
       "        1.48192329,  0.58972851,  0.07847677,  1.38081866, -0.92665483,\n",
       "       -0.70238255, -0.73982969,  0.93952313, -0.51508744, -0.38694504,\n",
       "       -2.47577512,  0.94221022,  1.10680504, -0.05306652, -0.25147923,\n",
       "        0.60611724,  0.3659832 , -0.33859742, -0.64359524,  0.53254989,\n",
       "       -0.02442218, -0.67338042, -1.02466644, -0.92629598,  0.22422437,\n",
       "        0.51508884, -0.52802302, -0.87334133, -1.13783232,  1.00284258,\n",
       "       -0.93107044,  0.47728973,  0.8411279 , -0.82846013,  0.862197  ,\n",
       "       -1.28258754, -0.44124708, -0.39879391, -1.41385178, -0.95823315,\n",
       "       -1.02550403, -0.93506437,  1.53775947,  0.48332699, -0.96745398])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 生成误差项（随机扰动项）$\\epsilon$， 服从标准正态分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.random.normal(loc=0.0, scale = 1.0, size=(n_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 生成输出Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_theta0 = 1 ## theta0的真实值\n",
    "true_theta1 = 5 ## theta1的真实值\n",
    "\n",
    "y = true_theta0 + true_theta1*x + e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.32923731,  -7.16638212,   3.10877543,  -1.60190769,\n",
       "        -1.3969536 ,  -1.39167754,  -1.85301389,  11.01010765,\n",
       "        -0.29442565,   4.94834741,  -0.87581756,   0.32833046,\n",
       "         0.29807139,  11.48496226,  -3.50861901, -11.69077408,\n",
       "         4.41707948,  -2.96033472,   2.80205281,  -1.70904702,\n",
       "         1.4479437 ,   3.69011649,  14.49024055,   1.64018481,\n",
       "         3.98587546,  -8.42481847,   7.99304026,   2.82230899,\n",
       "         1.52630761,  -4.71756069,  -0.34753396,   7.41768323,\n",
       "         3.18416632,  -2.68753459,   1.50251375,  -1.81041208,\n",
       "       -10.38252828,  -3.38692901,  -0.27550106,   4.87383952,\n",
       "         4.01186224,  -1.89741417,   7.85375635,  -8.11705784,\n",
       "         4.78146176,  -2.56424827,  -1.61991413,   2.75432777,\n",
       "         3.23374325,   7.90789787,  -2.79160518,   0.51737102,\n",
       "         0.66436404,   2.46588962,   5.407513  ,  10.35762832,\n",
       "         3.62267122,   1.31928176,   8.67470548,  -3.22718713,\n",
       "        -2.66046195,  -1.77976574,   5.8112175 ,  -1.40661994,\n",
       "        -0.79024943, -11.42846191,   7.34464178,   6.54603509,\n",
       "         1.28828386,  -1.42663087,   3.0018058 ,   1.63569109,\n",
       "         0.55645873,  -0.6266836 ,   4.19065557,  -0.9536452 ,\n",
       "        -2.59420213,  -6.87124996,  -4.7138613 ,   3.11504601,\n",
       "         5.27337862,  -1.61693872,  -4.77203895,  -5.49819422,\n",
       "         4.29093009,  -3.57943873,   2.9303297 ,   4.98907253,\n",
       "        -3.61543396,   6.79600986,  -4.86496224,  -2.06526656,\n",
       "         1.24444566,  -6.16182291,  -2.8374103 ,  -5.24899509,\n",
       "        -3.89968188,   7.86567119,   2.25713532,  -4.15137719])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 定义代价函数(cost function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归模型$h(x)=\\theta_0+\\theta_1x$的成本函数为平均均方误差：$J(\\theta_0, \\theta_1)=\\frac{1}{2m}\\sum_{i=1}^m (h(x^{(i)}) - y^{(i)})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_fnc(x, y, theta0, theta1):\n",
    "    m = x.shape[0] ## m为实例数\n",
    "    \n",
    "    ## 计算一元线性回归的成本：用for循环计算所有实例的均方误差和\n",
    "    cost = 0 # 成本的初始值为0     \n",
    "    for i in range(m): # 对每一个实例i，计算均方误差\n",
    "        h_theta = theta0 + theta1*x[i]  ## h(xi)\n",
    "        cost = cost + (h_theta - y[i])**2  \n",
    "    \n",
    "    average_cost = 1/(2*m)*cost ## 求平均\n",
    "        \n",
    "    return average_cost    # cost_fnc将返回平均均方误差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 定义梯度函数 (gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对$\\theta_0$求偏导：$\\frac{\\partial J}{\\partial \\theta_0}=\\frac{1}{m}\\sum_{i=1}^m(h(x^{(i)}) - y^{(i)})$\n",
    "\n",
    "对$\\theta_1$求偏导：$\\frac{\\partial J}{\\partial \\theta_1}=\\frac{1}{m}\\sum_{i=1}^m(h(x^{(i)}) - y^{(i)})x^{(i)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_fnc(x, y, theta0, theta1):\n",
    "    \n",
    "    m = x.shape[0]\n",
    "    \n",
    "    \n",
    "    dj_theta0 = 0  ## 用dJ/dtheta0代表J关于theta0的偏导，初始值为0\n",
    "    dj_theta1 = 0  ## 用dJ/dtheta1代表J关于theta1的偏导，初始值为0\n",
    "    \n",
    "    ## for循环：按上面公式对每个实例i求和\n",
    "    for i in range(m):\n",
    "        h_theta = theta0 + theta1*x[i]\n",
    "        dj_theta0_i = (h_theta - y[i])  \n",
    "        dj_theta1_i = (h_theta - y[i])*x[i]  \n",
    "        \n",
    "        dj_theta0 = dj_theta0 + dj_theta0_i # 求和\n",
    "        dj_theta1 = dj_theta1 + dj_theta1_i\n",
    "        \n",
    "    dj_theta0 = dj_theta0 / m\n",
    "    dj_theta1 = dj_theta1 / m\n",
    "    \n",
    "    return dj_theta0, dj_theta1 # gradient_fnc将返回J对于theta0和theta1的偏导"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 定义梯度下降算法函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数在每一次迭代的更新公式： $\\theta_j := \\theta_j - \\alpha \\frac{\\partial J}{\\partial \\theta_j}, j = 0, 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, theta0_init, theta1_init, alpha, max_iter, tol, cost_fnc, gradient_fnc):\n",
    "    \n",
    "    \"\"\"\n",
    "    theta0_init: theta0的初始值\n",
    "    theta1_init: theta1的初始值\n",
    "    alpha: 学习率\n",
    "    max_iter: 循环/迭代的最大次数\n",
    "    tol: 收敛条件:如果当前一步的代价J_current与上一步的代价J_old之差的绝对值<tol,则停止\n",
    "    cost_fnc: 代价函数\n",
    "    gradient_fnc: 梯度函数\n",
    "    \"\"\"\n",
    "    \n",
    "    Js = []  # 设置一个空List，将存储每次迭代的代价值\n",
    "    \n",
    "    theta0 = theta0_init # 设置theta0为其初始值\n",
    "    theta1 = theta1_init # 设置theta1为其初始值\n",
    "    \n",
    "    theta0_hist = [] # 设置一个空List，将存储每次迭代的theta0值\n",
    "    theta1_hist = [] # 设置一个空List，将存储每次迭代的theta1值\n",
    "\n",
    "    # i记录迭代\\循环次数\n",
    "    i = 0\n",
    "    while i < max_iter:\n",
    "        J_old = cost_fnc(x, y, theta0, theta1) # 计算上一步的代价, theta0, theta1为上一步的值\n",
    "        dj_theta0, dj_theta1 = gradient_fnc(x, y, theta0, theta1)  # 计算偏导，theta0、theta1为上一步的值\n",
    "        \n",
    "        # 更新theta0, theta 1\n",
    "        theta0 = theta0 - alpha * dj_theta0  # 填写theta0的更新公式\n",
    "        theta1 = theta1 - alpha * dj_theta1  # 填写theta1的更新公式\n",
    "        \n",
    "        J_current = cost_fnc(x, y, theta0, theta1)  # 计算更新后的代价\n",
    "        \n",
    "        Js.append(J_current) # 使用append函数，在Js中加入每次的代价J_current\n",
    "        theta0_hist.append(theta0) # 在theta0_hist中加入每次更新后的theta0\n",
    "        theta1_hist.append(theta1) # 在theta1_hist中加入每次更新后的theta1\n",
    "        \n",
    "        num_iter = i + 1 ## 记录迭代次数，在循环结束后，它存储的是最终的迭代次数\n",
    "        \n",
    "        if (abs(J_current - J_old) < tol): break # 如果当前一步的代价J_current与上一步的代价J_old之差的绝对值<tol,则停止\n",
    "            \n",
    "        i = i + 1 # 循环次数加1    \n",
    "        \n",
    "     \n",
    "    return theta0, theta1, Js, theta0_hist, theta1_hist, num_iter # # type: ignore 返回最终的theta0, theta1, 每次的代价Js，以及每次的theta0和theta1值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 在生成的数据上用梯度下降拟合线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta0_init = 0\n",
    "theta1_init = 0\n",
    "\n",
    "max_iter = 100000\n",
    "\n",
    "tol = 0.00000001\n",
    "alpha = 0.001\n",
    "\n",
    "theta0_final, theta1_final, Js, theta0_hist, theta1_hist, num_iter = gradient_descent(x, y, theta0_init, theta1_init, alpha, max_iter, tol, cost_fnc, gradient_fnc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 评价参数的估计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看估计的$\\theta_0$, $\\theta_1$值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0669681212701714, 5.1315310521131385, 8531)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta0_final, theta1_final,num_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算参数$\\theta$的均方误差： "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010892573468222774\n"
     ]
    }
   ],
   "source": [
    "MSE = ((theta0_final - true_theta0)**2 + (theta1_final - true_theta1)**2)/2  ## 计算参数的均方误差\n",
    "\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 查看代价J如何随迭代变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(len(Js)), Js, 'b') \n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel('Cost J')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: 结果好吗？梯度下降算法是否收敛？查看num_iter。如果没有收敛，请增大max_iter的值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q： 尝试改变步长alpha的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看每次迭代相对应的$\\theta_0$, $\\theta_1$，和代价J的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns = ['theta0', 'theta1', 'cost'])\n",
    "df['theta0'], df['theta1'], df['cost'] = theta0_hist, theta1_hist, Js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theta0</th>\n",
       "      <th>theta1</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.004519</td>\n",
       "      <td>12.437591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.009034</td>\n",
       "      <td>12.416880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001732</td>\n",
       "      <td>0.013545</td>\n",
       "      <td>12.396206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.018052</td>\n",
       "      <td>12.375569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002886</td>\n",
       "      <td>0.022556</td>\n",
       "      <td>12.354967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8526</th>\n",
       "      <td>1.066962</td>\n",
       "      <td>5.131520</td>\n",
       "      <td>0.547284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>1.066964</td>\n",
       "      <td>5.131523</td>\n",
       "      <td>0.547284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8528</th>\n",
       "      <td>1.066965</td>\n",
       "      <td>5.131525</td>\n",
       "      <td>0.547284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8529</th>\n",
       "      <td>1.066967</td>\n",
       "      <td>5.131528</td>\n",
       "      <td>0.547284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8530</th>\n",
       "      <td>1.066968</td>\n",
       "      <td>5.131531</td>\n",
       "      <td>0.547284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8531 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        theta0    theta1       cost\n",
       "0     0.000577  0.004519  12.437591\n",
       "1     0.001155  0.009034  12.416880\n",
       "2     0.001732  0.013545  12.396206\n",
       "3     0.002309  0.018052  12.375569\n",
       "4     0.002886  0.022556  12.354967\n",
       "...        ...       ...        ...\n",
       "8526  1.066962  5.131520   0.547284\n",
       "8527  1.066964  5.131523   0.547284\n",
       "8528  1.066965  5.131525   0.547284\n",
       "8529  1.066967  5.131528   0.547284\n",
       "8530  1.066968  5.131531   0.547284\n",
       "\n",
       "[8531 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 评价输出Y的预测准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = theta0_final + theta1_final*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "MSE_y = metrics.mean_squared_error(y_pred, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0945673639000426"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0945673639000426"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_y = sum((y_pred - y)**2)/len(y) ## 与上面等价\n",
    "MSE_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 与最小二乘法比较"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数LinearRegression()使用的是最小二乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression() ## 使用默认参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg.fit(x.reshape(-1, 1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0687280661760497\n",
      "[5.13484024]\n"
     ]
    }
   ],
   "source": [
    "print (linreg.intercept_)\n",
    "print (linreg.coef_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
